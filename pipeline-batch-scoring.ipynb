{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/pipeline-batch-scoring/pipeline-batch-scoring.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Azure ML service"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using Azure Machine Learning Pipelines for batch prediction\n\nIn this notebook we will demonstrate how to run a batch scoring job using Azure Machine Learning pipelines. Our example job will be to take an already-trained image classification model, and run that model on some unlabeled images. The image classification model that we'll use is the __[Inception-V3 model](https://arxiv.org/abs/1512.00567)__  and we'll run this model on unlabeled images from the __[ImageNet](http://image-net.org/)__ dataset. \n\nThe outline of this notebook is as follows:\n\n- Register the pretrained inception model into the model registry. \n- Store the dataset images in a blob container.\n- Use the registered model to do batch scoring on the images in the data blob container."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "> Documentation : https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-run-batch-predictions "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "> Lien : https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/machine-learning-pipelines/pipeline-batch-scoring "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prerequisites\nIf you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment\nfrom azureml.core.compute import AmlCompute, ComputeTarget\nfrom azureml.core.datastore import Datastore\nfrom azureml.core.runconfig import CondaDependencies, RunConfiguration\nfrom azureml.data.data_reference import DataReference\nfrom azureml.pipeline.core import Pipeline, PipelineData\nfrom azureml.pipeline.steps import PythonScriptStep",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\nprint(\"Version Azure ML service :\", azureml.core.VERSION)\n\nimport os\nsubscription_id = os.environ.get(\"SUBSCRIPTION_ID\", \"A COMPLETER\")\nresource_group = os.environ.get(\"RESOURCE_GROUP\", \"A COMPLETER\")\nworkspace_name = os.environ.get(\"WORKSPACE_NAME\", \"A COMPLETER\")\n\n\nfrom azureml.core import Workspace\ntry:\n   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n   ws.write_config()\n   print(\"Le workspace Azure ML service a été trouvé : OK\")\nexcept:\n   print(\"Le workspace Azure ML service n'a pas été trouvé\")",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Version Azure ML service : 1.0.45\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FKHMPJFBZ to authenticate.\nInteractive authentication successfully completed.\nLe workspace Azure ML service a été trouvé : OK\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom azureml.core import Workspace\n\nws = Workspace.from_config()\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n           'Resource group: ' + ws.resource_group, sep = '\\n')\n",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Workspace name: azuremlservice\nAzure region: westeurope\nResource group: azuremlserviceresourcegroup\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Set up machine learning resources"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Set up datastores\nFirst, let's access the datastore that has the model, labels, and images. \n\n### Create a datastore that points to a blob container containing sample images\n\nWe have created a public blob container `sampledata` on an account named `pipelinedata`, containing images from the ImageNet evaluation set. In the next step, we create a datastore with the name `images_datastore`, which points to this container. In the call to `register_azure_blob_container` below, setting the `overwrite` flag to `True` overwrites any datastore that was created previously with that name. \n\nThis step can be changed to point to your blob container by providing your own `datastore_name`, `container_name`, and `account_name`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "account_name = \"pipelinedata\"\ndatastore_name=\"images_datastore\"\ncontainer_name=\"sampledata\"\n\nbatchscore_blob = Datastore.register_azure_blob_container(ws, \n                      datastore_name=datastore_name, \n                      container_name= container_name, \n                      account_name=account_name, \n                      overwrite=True)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, let's specify the default datastore for the outputs."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def_data_store = ws.get_default_datastore()",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Configure data references\nNow you need to add references to the data, as inputs to the appropriate pipeline steps in your pipeline. A data source in a pipeline is represented by a DataReference object. The DataReference object points to data that lives in, or is accessible from, a datastore. We need DataReference objects corresponding to the following: the directory containing the input images, the directory in which the pretrained model is stored, the directory containing the labels, and the output directory."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "input_images = DataReference(datastore=batchscore_blob, \n                             data_reference_name=\"input_images\",\n                             path_on_datastore=\"batchscoring/images\",\n                             mode=\"download\"\n                            )\nmodel_dir = DataReference(datastore=batchscore_blob, \n                          data_reference_name=\"input_model\",\n                          path_on_datastore=\"batchscoring/models\",\n                          mode=\"download\"                          \n                         )\nlabel_dir = DataReference(datastore=batchscore_blob, \n                          data_reference_name=\"input_labels\",\n                          path_on_datastore=\"batchscoring/labels\",\n                          mode=\"download\"                          \n                         )\noutput_dir = PipelineData(name=\"scores\", \n                          datastore=def_data_store, \n                          output_path_on_compute=\"batchscoring/results\")",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create and attach Compute targets\nUse the below code to create and attach Compute targets. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# choose a name for your cluster\naml_compute_name = os.environ.get(\"AML_COMPUTE_NAME\", \"gpu-cluster\")\ncluster_min_nodes = os.environ.get(\"AML_COMPUTE_MIN_NODES\", 0)\ncluster_max_nodes = os.environ.get(\"AML_COMPUTE_MAX_NODES\", 1)\nvm_size = os.environ.get(\"AML_COMPUTE_SKU\", \"STANDARD_NC6\")\n\n\nif aml_compute_name in ws.compute_targets:\n    compute_target = ws.compute_targets[aml_compute_name]\n    if compute_target and type(compute_target) is AmlCompute:\n        print('found compute target. just use it. ' + aml_compute_name)\nelse:\n    print('creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, # NC6 is GPU-enabled\n                                                                vm_priority = 'lowpriority', # optional\n                                                                min_nodes = cluster_min_nodes, \n                                                                max_nodes = cluster_max_nodes)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, aml_compute_name, provisioning_config)\n    \n    # can poll for a minimum number of nodes and for a specific timeout. \n    # if no min node count is provided it will use the scale settings for the cluster\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n    \n     # For a more detailed view of current Azure Machine Learning Compute  status, use get_status()\n    print(compute_target.get_status().serialize())",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "creating a new compute target...\nCreating\nSucceeded\nAmlCompute wait for completion finished\nMinimum number of nodes requested have been provisioned\n{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-07-11T07:16:31.004000+00:00', 'errors': None, 'creationTime': '2019-07-11T07:16:28.237320+00:00', 'modifiedTime': '2019-07-11T07:16:44.402569+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'LowPriority', 'vmSize': 'STANDARD_NC6'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prepare the Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Download the Model\n\nDownload and extract the model from http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz to `\"models\"`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create directory for model\nmodel_dir = 'models'\nif not os.path.isdir(model_dir):\n    os.mkdir(model_dir)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tarfile\nimport urllib.request\n\nurl=\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\"\nresponse = urllib.request.urlretrieve(url, \"model.tar.gz\")\ntar = tarfile.open(\"model.tar.gz\", \"r:gz\")\ntar.extractall(model_dir)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ls *.gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Register the model with Workspace"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import shutil\nfrom azureml.core.model import Model\n\n# register downloaded model \nmodel = Model.register(model_path = \"models/inception_v3.ckpt\",\n                       model_name = \"inception\", # this is the name the model is registered as\n                       tags = {'pretrained': \"inception\"},\n                       description = \"Imagenet trained tensorflow inception\",\n                       workspace = ws)\n# remove the downloaded dir after registration if you wish\nshutil.rmtree(\"models\")",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model inception\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ls *.*",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "batch_scoring.py  model.tar.gz  pipeline-batch-scoring.ipynb  README.md\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Write your scoring script"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To do the scoring, we use a batch scoring script `batch_scoring.py`, which is located in the same directory that this notebook is in. You can take a look at this script to see how you might modify it for your custom batch scoring task.\n\nThe python script `batch_scoring.py` takes input images, applies the image classification model to these images, and outputs a classification result to a results file.\n\nThe script `batch_scoring.py` takes the following parameters:\n\n- `--model_name`: the name of the model being used, which is expected to be in the `model_dir` directory\n- `--label_dir` : the directory holding the `labels.txt` file \n- `--dataset_path`: the directory containing the input images\n- `--output_dir` : the script will run the model on the data and output a `results-label.txt` to this directory\n- `--batch_size` : the batch size used in running the model.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Build and run the batch scoring pipeline\nYou have everything you need to build the pipeline. Letâ€™s put all these together."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "###  Specify the environment to run the script\nSpecify the conda dependencies for your script. You will need this object when you create the pipeline step later on."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n\ncd = CondaDependencies.create(pip_packages=[\"tensorflow-gpu==1.13.1\", \"azureml-defaults\"])\n\n# Runconfig\namlcompute_run_config = RunConfiguration(conda_dependencies=cd)\namlcompute_run_config.environment.docker.enabled = True\namlcompute_run_config.environment.docker.gpu_support = True\namlcompute_run_config.environment.docker.base_image = DEFAULT_GPU_IMAGE\namlcompute_run_config.environment.spark.precache_packages = False",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Specify the parameters for your pipeline\nA subset of the parameters to the python script can be given as input when we re-run a `PublishedPipeline`. In the current example, we define `batch_size` taken by the script as such parameter."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.core.graph import PipelineParameter\nbatch_size_param = PipelineParameter(name=\"param_batch_size\", default_value=20)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create the pipeline step\nCreate the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use PythonScriptStep to create the pipeline step."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "inception_model_name = \"inception_v3.ckpt\"\n\nbatch_score_step = PythonScriptStep(\n    name=\"batch_scoring\",\n    script_name=\"batch_scoring.py\",\n    arguments=[\"--dataset_path\", input_images, \n               \"--model_name\", \"inception\",\n               \"--label_dir\", label_dir, \n               \"--output_dir\", output_dir, \n               \"--batch_size\", batch_size_param],\n    compute_target=compute_target,\n    inputs=[input_images, label_dir],\n    outputs=[output_dir],\n    runconfig=amlcompute_run_config\n)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Run the pipeline\nAt this point you can run the pipeline and examine the output it produced. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\npipeline_run = Experiment(ws, 'batch_scoring').submit(pipeline, pipeline_params={\"param_batch_size\": 20})",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Created step batch_scoring [8b54b364][93158eba-9784-49b6-9ba8-bc06440b7ab8], (This step will run and generate new outputs)\nUsing data reference input_images for StepId [ffd21e0a][157dc06e-a8eb-4200-aeab-38737336ad9b], (Consumers of this data are eligible to reuse prior runs.)\nUsing data reference input_labels for StepId [282839d9][12afdacf-2cb9-4e97-a609-9fe8623e7f03], (Consumers of this data are eligible to reuse prior runs.)\nSubmitted pipeline run: f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Monitor the run"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(pipeline_run).show()",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a554af271bda4871a5c199058f4870d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipeline_run.wait_for_completion(show_output=True)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "PipelineRunId: f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f\nLink to Portal: https://mlworkspace.azure.ai/portal/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourceGroups/azuremlserviceresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/azuremlservice/experiments/batch_scoring/runs/f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f', 'status': 'Completed', 'startTimeUtc': '2019-07-11T07:46:47.297712Z', 'endTimeUtc': '2019-07-11T07:57:21.304189Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{\"param_batch_size\":\"20\"}'}, 'logFiles': {'logs/azureml/stderrlogs.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=7o5Wt%2FR3mMQYXHhWCnm3H7O6CqFRknpKUzdE%2BqAjSfM%3D&st=2019-07-11T07%3A49%3A00Z&se=2019-07-11T15%3A59%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=%2FMTbxdaeAy%2Bs9vefKyeu03awcABsdhqCwHHEVksROcM%3D&st=2019-07-11T07%3A49%3A00Z&se=2019-07-11T15%3A59%3A00Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.f6e5e073-a07a-4c87-8f7b-2da6ddba9d6f/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=ZONrK%2BJ5LKxA979K1Cvr%2B1IVnrH8p%2BAxChGiS1lGTBQ%3D&st=2019-07-11T07%3A49%3A00Z&se=2019-07-11T15%3A59%3A00Z&sp=r'}}\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Download and review output"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "step_run = list(pipeline_run.get_children())[0]\nstep_run.download_file(\"./outputs/result-labels.txt\")",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.read_csv(\"result-labels.txt\", delimiter=\":\", header=None)\ndf.columns = [\"Filename\", \"Prediction\"]\ndf.head()",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ILSVRC2012_val_00000102.JPEG</td>\n      <td>Rhodesian ridgeback</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ILSVRC2012_val_00000103.JPEG</td>\n      <td>tripod</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ILSVRC2012_val_00000104.JPEG</td>\n      <td>typewriter keyboard</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ILSVRC2012_val_00000105.JPEG</td>\n      <td>silky terrier</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ILSVRC2012_val_00000106.JPEG</td>\n      <td>Windsor tie</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                       Filename            Prediction\n0  ILSVRC2012_val_00000102.JPEG   Rhodesian ridgeback\n1  ILSVRC2012_val_00000103.JPEG                tripod\n2  ILSVRC2012_val_00000104.JPEG   typewriter keyboard\n3  ILSVRC2012_val_00000105.JPEG         silky terrier\n4  ILSVRC2012_val_00000106.JPEG           Windsor tie"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%ls *.txt",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "result-labels.txt\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Publish a pipeline and rerun using a REST call"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a published pipeline\nOnce you are satisfied with the outcome of the run, you can publish the pipeline to run it with different input values later. When you publish a pipeline, you will get a REST endpoint that accepts invoking of the pipeline with the set of parameters you have already incorporated above using PipelineParameter."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\npublished_pipeline = pipeline_run.publish_pipeline(\n    name=\"Inception_v3_scoring\", description=\"Batch scoring using Inception v3 model\", version=\"1.0\")\n\npublished_pipeline",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 153 ms, sys: 53 ms, total: 206 ms\nWall time: 3.28 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Get published pipeline\n\nYou can get the published pipeline using **pipeline id**.\n\nTo get all the published pipelines for a given workspace(ws): \n```css\nall_pub_pipelines = PublishedPipeline.get_all(ws)\n```"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.pipeline.core import PublishedPipeline\n\npipeline_id = published_pipeline.id # use your published pipeline id\npublished_pipeline = PublishedPipeline.get(ws, pipeline_id)\n\npublished_pipeline",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 60.7 ms, sys: 3.28 ms, total: 64 ms\nWall time: 741 ms\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Rerun the pipeline using the REST endpoint"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Get AAD token\n[This notebook](https://aka.ms/pl-restep-auth) shows how to authenticate to AML workspace."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.authentication import InteractiveLoginAuthentication\nimport requests\n\nauth = InteractiveLoginAuthentication()\naad_token = auth.get_authentication_header()\n",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Run published pipeline"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nrest_endpoint = published_pipeline.endpoint\n# specify batch size when running the pipeline\nresponse = requests.post(rest_endpoint, \n                         headers=aad_token, \n                         json={\"ExperimentName\": \"batch_scoring\",\n                               \"ParameterAssignments\": {\"param_batch_size\": 50}})\nrun_id = response.json()[\"Id\"]",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 31 ms, sys: 0 ns, total: 31 ms\nWall time: 2.73 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Monitor the new run"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.core.run import PipelineRun\npublished_pipeline_run = PipelineRun(ws.experiments[\"batch_scoring\"], run_id)\n\nRunDetails(published_pipeline_run).show()",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fbc14648c374c0190432ce1e756d92a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "> Fin"
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "sanpil"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}